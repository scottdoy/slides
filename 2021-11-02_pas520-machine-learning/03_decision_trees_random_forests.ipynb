{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03-decision-trees-random-forests.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h67cJPWWXXW2"
      },
      "source": [
        "# Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DvjWJrQR5TB6"
      },
      "source": [
        "In this notebook, I'll be demonstrating decision trees and random forests.\n",
        "\n",
        "If you haven't already, please refer to [01-data-exploration.ipynb](), as that notebook describes most of the data loading and pre-processing steps that we'll perform at the beginning of this notebook.\n",
        "\n",
        "Links of interest:\n",
        "- [Scikit-Learn: Decision Trees](https://scikit-learn.org/stable/modules/tree.html)\n",
        "- [Scikit-Learn: Bagging Meta Estimator](https://scikit-learn.org/stable/modules/ensemble.html#bagging-meta-estimator)\n",
        "- [Scikit-Learn: Forests of Randomized Trees](https://scikit-learn.org/stable/modules/ensemble.html#forests-of-randomized-trees)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tauacz9lXZ9X"
      },
      "source": [
        "# Imports, Data Access / Loading, and Pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymicpVB5B7O5"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# We use two different plotting libraries, depending on which kind of plot we want\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Set an option for Pandas to display smaller floating-point numbers\n",
        "pd.options.display.float_format = '{:,.2f}'.format\n",
        "\n",
        "# Turn off warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import StratifiedShuffleSplit, cross_val_score\n",
        "from sklearn.pipeline import Pipeline, make_pipeline\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn import metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhEwadWoGOcW"
      },
      "source": [
        "# Need to get Google Drive access\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFq062M3Glre"
      },
      "source": [
        "# Load the dataset into a Pandas dataframe\n",
        "data_dir = os.path.join('/content/gdrive/My Drive/classes/be432-2021/notebooks/wisconsin_breast_cancer_data.csv')\n",
        "df = pd.read_csv(data_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8snsECMQqROj"
      },
      "source": [
        "label_encoder = LabelEncoder()\n",
        "diagnosis_cat = df['diagnosis']\n",
        "\n",
        "# Fit the encoder to the categories, and immediately \n",
        "diagnosis_lab = label_encoder.fit_transform(diagnosis_cat)\n",
        "\n",
        "# Add the diagnosis label back to the dataframe\n",
        "df['diagnosis_label'] = diagnosis_lab"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSjeHzVKGkED"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcadRPrJqTGM"
      },
      "source": [
        "# Create the splitting object\n",
        "split = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=25)\n",
        "\n",
        "# Apply the split to the data frame using the \"diagnosis\" column as our label\n",
        "for train_index, test_index in split.split(df, df[\"diagnosis\"]):\n",
        "    train_set = df.loc[train_index]\n",
        "    test_set = df.loc[test_index]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOAvTps1vXvc"
      },
      "source": [
        "training_values = train_set.drop(['id','diagnosis', 'diagnosis_label'], axis=1)\n",
        "training_labels = train_set[['diagnosis_label']].copy()\n",
        "\n",
        "testing_values = test_set.drop(['id','diagnosis', 'diagnosis_label'], axis=1)\n",
        "testing_labels = test_set[['diagnosis_label']].copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlUNVmuUqTt9"
      },
      "source": [
        "# Separate out our training data into classes for easier plotting\n",
        "malignant = training_values.loc[training_labels['diagnosis_label'] == 1,:]\n",
        "benign = training_values.loc[training_labels['diagnosis_label'] == 0,:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYvrOozCvo7t"
      },
      "source": [
        "# Decision Trees"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oIRgg2l7XgXW"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RNp1geYvXnT"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import tree\n",
        "\n",
        "tree_clf = DecisionTreeClassifier()\n",
        "tree_clf.fit(training_values, training_labels)\n",
        "\n",
        "# Make predictions\n",
        "tree_predictions = tree_clf.predict(testing_values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88tZnbcjH1O2"
      },
      "source": [
        "tree_predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9E9zIlBZ4JBy"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKWm16FEyTu2"
      },
      "source": [
        "print(55 * \"=\")\n",
        "print(\"Decision Trees\")\n",
        "print(55 * \"-\")\n",
        "print(metrics.classification_report(testing_labels, tree_predictions, target_names=['Benign', 'Malignant']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8P2GKfw32-c"
      },
      "source": [
        "# Print confusion matrix\n",
        "print(55 * \"=\")\n",
        "print(\"Decision Trees\")\n",
        "print(55 * \"-\")\n",
        "tree_matrix = metrics.confusion_matrix(testing_labels, tree_predictions)\n",
        "\n",
        "print(\"True Positive: {}\".format(tree_matrix[1][1]))\n",
        "print(\"True Negative: {}\".format(tree_matrix[0][0]))\n",
        "print(\"False Positive: {}\".format(tree_matrix[0][1]))\n",
        "print(\"False Negative: {}\".format(tree_matrix[1][0]))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1TcSDjtxNUoT"
      },
      "source": [
        "## Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lwhWXEdFcyh"
      },
      "source": [
        "# Print the actual decision tree\n",
        "import graphviz\n",
        "import pydotplus\n",
        "\n",
        "plot_colors = \"ryb\"\n",
        "plot_step = 0.02\n",
        "\n",
        "for pairidx, pair in enumerate([[0, 1]]):\n",
        "    # We only take the two corresponding features\n",
        "    X = np.array(training_values.iloc[:, pair])\n",
        "    y = np.array(training_labels)\n",
        "\n",
        "    # Train\n",
        "    clf = DecisionTreeClassifier().fit(X, y)\n",
        "\n",
        "    # Plot the decision boundary\n",
        "    # plt.subplot(1, 1, pairidx + 1)\n",
        "\n",
        "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
        "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
        "    xx, yy = np.meshgrid(np.arange(x_min, x_max, plot_step),\n",
        "                         np.arange(y_min, y_max, plot_step))\n",
        "    plt.tight_layout(h_pad=0.5, w_pad=0.5, pad=2.5)\n",
        "\n",
        "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "    Z = Z.reshape(xx.shape)\n",
        "    cs = plt.contourf(xx, yy, Z, cmap=plt.cm.RdYlBu)\n",
        "\n",
        "    plt.xlabel(training_values.columns[pair[0]])\n",
        "    plt.ylabel(training_values.columns[pair[1]])\n",
        "\n",
        "    # Plot the training points\n",
        "    for i, color in zip(range(len(label_encoder.classes_)), plot_colors):\n",
        "        idx = np.where(y == i)\n",
        "        plt.scatter(X[idx, 0], X[idx, 1], c=color, label=label_encoder.classes_[i],\n",
        "                    cmap=plt.cm.RdYlBu, edgecolor='black', s=15)\n",
        "\n",
        "plt.suptitle(\"Decision surface of a decision tree using paired features\")\n",
        "plt.legend(loc='lower right', borderpad=0, handletextpad=0)\n",
        "plt.axis(\"tight\")\n",
        "plt.show()\n",
        "# plt.figure()\n",
        "# tree_clf = DecisionTreeClassifier().fit(training_values, training_labels)\n",
        "# tree.plot_tree(tree_clf, filled=True)\n",
        "# plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBYigrg1IF5d"
      },
      "source": [
        "dot_data = tree.export_graphviz(tree_clf, out_file=None, \n",
        "                                feature_names=training_values.columns,  \n",
        "                                class_names=label_encoder.classes_,  \n",
        "                                filled=True, rounded=True,  \n",
        "                                special_characters=True)  \n",
        "\n",
        "# Create the graph from the dot data\n",
        "pydot_graph = pydotplus.graph_from_dot_data(dot_data)\n",
        "\n",
        "# Set the output size\n",
        "pydot_graph.set_size('\"10,10!\"')\n",
        "\n",
        "# Create the graphviz object\n",
        "gvz_graph = graphviz.Source(pydot_graph.to_string())\n",
        "\n",
        "# Display\n",
        "gvz_graph"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_eeICVCiB9u"
      },
      "source": [
        "# Decision Trees: Random Subsamples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9XLIAILkDcx"
      },
      "source": [
        "Decision Trees are sensitive to training -- we can see this by randomly sub-sampling the training set and creating trees from it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqsdV91aiBQa"
      },
      "source": [
        "# Create a vector to randomly split the data\n",
        "n_training = len(training_values)\n",
        "idx_split = np.arange(0, n_training)\n",
        "np.random.shuffle(idx_split)\n",
        "\n",
        "training_values_a = training_values.iloc[idx_split[:int(n_training/2)], :]\n",
        "training_labels_a = training_labels.iloc[idx_split[:int(n_training/2)]]\n",
        "\n",
        "training_values_b = training_values.iloc[idx_split[int(n_training/2):], :]\n",
        "training_labels_b = training_labels.iloc[idx_split[int(n_training/2):]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OklYKwhMjX-0"
      },
      "source": [
        "tree_a = DecisionTreeClassifier()\n",
        "tree_a.fit(training_values_a, training_labels_a)\n",
        "\n",
        "tree_b = DecisionTreeClassifier()\n",
        "tree_b.fit(training_values_b, training_labels_b)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikKlaoWRjj7m"
      },
      "source": [
        "dot_data = tree.export_graphviz(tree_a, out_file=None, \n",
        "                                feature_names=training_values.columns,  \n",
        "                                class_names=label_encoder.classes_,  \n",
        "                                filled=True, rounded=True,  \n",
        "                                special_characters=True)  \n",
        "\n",
        "# Create the graph from the dot data\n",
        "pydot_graph = pydotplus.graph_from_dot_data(dot_data)\n",
        "\n",
        "# Set the output size\n",
        "pydot_graph.set_size('\"10,10!\"')\n",
        "\n",
        "# Create the graphviz object\n",
        "gvz_graph = graphviz.Source(pydot_graph.to_string())\n",
        "\n",
        "# Display\n",
        "gvz_graph"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqQeQ9SdjpMv"
      },
      "source": [
        "dot_data = tree.export_graphviz(tree_b, out_file=None, \n",
        "                                feature_names=training_values.columns,  \n",
        "                                class_names=label_encoder.classes_,  \n",
        "                                filled=True, rounded=True,  \n",
        "                                special_characters=True)  \n",
        "\n",
        "# Create the graph from the dot data\n",
        "pydot_graph = pydotplus.graph_from_dot_data(dot_data)\n",
        "\n",
        "# Set the output size\n",
        "pydot_graph.set_size('\"10,10!\"')\n",
        "\n",
        "# Create the graphviz object\n",
        "gvz_graph = graphviz.Source(pydot_graph.to_string())\n",
        "\n",
        "# Display\n",
        "gvz_graph"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVbJrsPpKW85"
      },
      "source": [
        "# Random Forests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgdtdX3NLDzA"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1DrFIdqIfs6"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "max_features = 10\n",
        "n_estimators = 5\n",
        "\n",
        "rf_clf = RandomForestClassifier(max_features=max_features, n_estimators=n_estimators)\n",
        "rf_clf.fit(training_values, training_labels)\n",
        "\n",
        "# Make predictions\n",
        "rf_predictions = rf_clf.predict(testing_values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZ39v5p2LHEg"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5W-IaBk9Ihx7"
      },
      "source": [
        "print(55 * \"=\")\n",
        "print(f\"Random Forests with {max_features} features and {n_estimators} trees:\")\n",
        "print(55 * \"-\")\n",
        "print(metrics.classification_report(testing_labels, rf_predictions, target_names=['Benign', 'Malignant']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4j_txx6yNaaR"
      },
      "source": [
        "# Print confusion matrix\n",
        "print(55 * \"=\")\n",
        "print(f\"Random Forests with {max_features} features and {n_estimators} trees:\")\n",
        "print(55 * \"-\")\n",
        "rf_matrix = metrics.confusion_matrix(testing_labels, rf_predictions)\n",
        "\n",
        "print(\"True Positive: {}\".format(rf_matrix[1][1]))\n",
        "print(\"True Negative: {}\".format(rf_matrix[0][0]))\n",
        "print(\"False Positive: {}\".format(rf_matrix[0][1]))\n",
        "print(\"False Negative: {}\".format(rf_matrix[1][0]))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGzyqx2_LNHA"
      },
      "source": [
        "for max_features in [10, 20, 30]:\n",
        "  for n_estimators in [5, 10, 30, 50, 100]:\n",
        "    rf_clf = RandomForestClassifier(max_features=max_features, n_estimators=n_estimators)\n",
        "    rf_clf.fit(training_values, training_labels)\n",
        "\n",
        "    # Make predictions\n",
        "    rf_predictions = rf_clf.predict(testing_values)\n",
        "    print(55 * \"=\")\n",
        "    print(f\"Random Forests with {max_features} features and {n_estimators} trees:\")\n",
        "    print(55 * \"-\")\n",
        "    print(metrics.classification_report(testing_labels, rf_predictions, target_names=['Benign', 'Malignant']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFJ8sJljLyOK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}