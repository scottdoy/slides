{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "04-ensemble-methods-and-evaluation.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "h67cJPWWXXW2",
        "tauacz9lXZ9X",
        "LYvrOozCvo7t",
        "oIRgg2l7XgXW",
        "9E9zIlBZ4JBy",
        "V3XWuDTwvXPi",
        "oXYGusYW0AsP",
        "AgdtdX3NLDzA"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h67cJPWWXXW2"
      },
      "source": [
        "# Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DvjWJrQR5TB6"
      },
      "source": [
        "In this notebook, I'll be demonstrating ensemble methods.\n",
        "\n",
        "We will start with bagging and boosting, and then show an example of AdaBoost (Adaptive Boosting).\n",
        "\n",
        "If you haven't already, please refer to [01-data-exploration.ipynb](), as that notebook describes most of the data loading and pre-processing steps that we'll perform at the beginning of this notebook.\n",
        "\n",
        "Links of interest:\n",
        "- [Scikit-Learn: Decision Trees](https://scikit-learn.org/stable/modules/tree.html)\n",
        "- [Scikit-Learn: Bagging Meta Estimator](https://scikit-learn.org/stable/modules/ensemble.html#bagging-meta-estimator)\n",
        "- [Scikit-Learn: Forests of Randomized Trees](https://scikit-learn.org/stable/modules/ensemble.html#forests-of-randomized-trees)\n",
        "- [Scikit-Learn: Ensemble Methods: AdaBoost](https://scikit-learn.org/stable/modules/ensemble.html#adaboost)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tauacz9lXZ9X"
      },
      "source": [
        "# Imports, Data Access / Loading, and Pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymicpVB5B7O5"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# We use two different plotting libraries, depending on which kind of plot we want\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Set an option for Pandas to display smaller floating-point numbers\n",
        "pd.options.display.float_format = '{:,.2f}'.format\n",
        "\n",
        "# Turn off warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import StratifiedShuffleSplit, cross_val_score\n",
        "from sklearn.pipeline import Pipeline, make_pipeline\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn import metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhEwadWoGOcW"
      },
      "source": [
        "# Need to get Google Drive access\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFq062M3Glre"
      },
      "source": [
        "# Load the dataset into a Pandas dataframe\n",
        "data_dir = os.path.join('/content/gdrive/My Drive/classes/be432-2021/notebooks/wisconsin_breast_cancer_data.csv')\n",
        "df = pd.read_csv(data_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6IoUP48zEt4y"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8snsECMQqROj"
      },
      "source": [
        "label_encoder = LabelEncoder()\n",
        "diagnosis_cat = df['diagnosis']\n",
        "\n",
        "# Fit the encoder to the categories, and immediately \n",
        "diagnosis_lab = label_encoder.fit_transform(diagnosis_cat)\n",
        "\n",
        "# Add the diagnosis label back to the dataframe\n",
        "df['diagnosis_label'] = diagnosis_lab"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcadRPrJqTGM"
      },
      "source": [
        "# Create the splitting object\n",
        "split = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=25)\n",
        "\n",
        "# Apply the split to the data frame using the \"diagnosis\" column as our label\n",
        "for train_index, test_index in split.split(df, df[\"diagnosis\"]):\n",
        "    train_set = df.loc[train_index]\n",
        "    test_set = df.loc[test_index]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOAvTps1vXvc"
      },
      "source": [
        "training_values = train_set.drop(['id','diagnosis', 'diagnosis_label'], axis=1)\n",
        "training_labels = train_set[['diagnosis_label']].copy()\n",
        "\n",
        "testing_values = test_set.drop(['id','diagnosis', 'diagnosis_label'], axis=1)\n",
        "testing_labels = test_set[['diagnosis_label']].copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlUNVmuUqTt9"
      },
      "source": [
        "# Separate out our training data into classes for easier plotting\n",
        "malignant = training_values.loc[training_labels['diagnosis_label'] == 1,:]\n",
        "benign = training_values.loc[training_labels['diagnosis_label'] == 0,:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYvrOozCvo7t"
      },
      "source": [
        "# Bagging"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oIRgg2l7XgXW"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RNp1geYvXnT"
      },
      "source": [
        "# Import our classifiers\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import tree\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Import the bagging class\n",
        "from sklearn.ensemble import BaggingClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjRAQbHYt_tS"
      },
      "source": [
        "# Construct individual classifiers as well as the bagged version of each one\n",
        "tree_clf = DecisionTreeClassifier()\n",
        "knn_clf = KNeighborsClassifier()\n",
        "\n",
        "\n",
        "tree_bag = BaggingClassifier(tree_clf,\n",
        "                            max_samples=0.5, max_features=0.5)\n",
        "knn_bag = BaggingClassifier(knn_clf,\n",
        "                            max_samples=0.5, max_features=0.5)\n",
        "\n",
        "# Train each of the classifiers on the training data\n",
        "tree_clf.fit(training_values, training_labels)\n",
        "knn_clf.fit(training_values, training_labels)\n",
        "\n",
        "tree_bag.fit(training_values, training_labels)\n",
        "knn_bag.fit(training_values, training_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9E9zIlBZ4JBy"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yli2J8Ojud4D"
      },
      "source": [
        "# Perform prediction for each of the classifiers\n",
        "tree_clf_predictions = tree_clf.predict(testing_values)\n",
        "knn_clf_predictions  = knn_clf.predict(testing_values)\n",
        "tree_bag_predictions = tree_bag.predict(testing_values)\n",
        "knn_bag_predictions  = knn_bag.predict(testing_values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQy5Q564MHB3"
      },
      "source": [
        "print(tree_clf_predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKWm16FEyTu2"
      },
      "source": [
        "print(55 * \"=\")\n",
        "print(\"Decision Tree Classifier\")\n",
        "print(55 * \"-\")\n",
        "print(metrics.classification_report(testing_labels, tree_clf_predictions, target_names=['Benign', 'Malignant']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kaLthNpku2qt"
      },
      "source": [
        "print(55 * \"=\")\n",
        "print(\"Decision Tree Bagging\")\n",
        "print(55 * \"-\")\n",
        "print(metrics.classification_report(testing_labels, tree_bag_predictions, target_names=['Benign', 'Malignant']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQvgoZI-vCmV"
      },
      "source": [
        "print(55 * \"=\")\n",
        "print(\"KNN Classifier\")\n",
        "print(55 * \"-\")\n",
        "print(metrics.classification_report(testing_labels, knn_clf_predictions, target_names=['Benign', 'Malignant']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Yy9C3pdvJKq"
      },
      "source": [
        "print(55 * \"=\")\n",
        "print(\"KNN Bagging\")\n",
        "print(55 * \"-\")\n",
        "print(metrics.classification_report(testing_labels, knn_bag_predictions, target_names=['Benign', 'Malignant']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3XWuDTwvXPi"
      },
      "source": [
        "# Testing Robustness and Stability"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQsI_PlivZud"
      },
      "source": [
        "#  How many trials to run\n",
        "n_repeat = 50\n",
        "\n",
        "# Size of the training set to use in each trial\n",
        "n_train = 200"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4lQryI6vhEO"
      },
      "source": [
        "estimators = [(\"Tree\", DecisionTreeClassifier()),\n",
        "              (\"Bagging(Tree)\", BaggingClassifier(DecisionTreeClassifier())),\n",
        "              (\"KNN\", KNeighborsClassifier(n_neighbors=3)),\n",
        "              (\"Bagging(KNN)\", BaggingClassifier(KNeighborsClassifier(n_neighbors=3)))]\n",
        "\n",
        "n_estimators = len(estimators)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAdIXz8-vl9w"
      },
      "source": [
        "# Loop over estimators to compare\n",
        "for n, (name, estimator) in enumerate(estimators):\n",
        "\n",
        "    # Compute predictions\n",
        "    y_scores = []\n",
        "\n",
        "    for i in range(n_repeat):\n",
        "        training_idx = np.arange(0, len(training_labels))\n",
        "        np.random.shuffle(training_idx)\n",
        "        training_idx = training_idx[:n_train]\n",
        "        \n",
        "        estimator.fit(training_values.iloc[training_idx,:], training_labels.iloc[training_idx])\n",
        "\n",
        "        y_predict = estimator.predict(testing_values)\n",
        "        y_scores.append(metrics.f1_score(testing_labels, y_predict))\n",
        "\n",
        "    # Print the results\n",
        "    print(f'F-1 Scores for {name}:')\n",
        "    print(f'Average Score: {np.mean(y_scores):.2}')\n",
        "    print(f'STD of Score: {np.std(y_scores):.2}')\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXYGusYW0AsP"
      },
      "source": [
        "# AdaBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9PaThQg0AF9"
      },
      "source": [
        "# Create and fit an AdaBoosted decision tree\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "bdt = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1),\n",
        "                         algorithm=\"SAMME\",\n",
        "                         n_estimators=200)\n",
        "\n",
        "# Train using just two features so we can visualize\n",
        "X_train = training_values.iloc[:,:2]\n",
        "y_train = training_labels.iloc[:]\n",
        "\n",
        "bdt.fit(X_train, y_train)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXRt426U0R5V"
      },
      "source": [
        "# Plot the decision boundaries\n",
        "plt.figure(figsize=(10, 10))\n",
        "plot_step = 0.02\n",
        "\n",
        "x_min, x_max = X_train.iloc[:, 0].min() - 1, X_train.iloc[:, 0].max() + 1\n",
        "y_min, y_max = X_train.iloc[:, 1].min() - 1, X_train.iloc[:, 1].max() + 1\n",
        "xx, yy = np.meshgrid(np.arange(x_min, x_max, plot_step),\n",
        "                     np.arange(y_min, y_max, plot_step))\n",
        "\n",
        "Z = bdt.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "Z = Z.reshape(xx.shape)\n",
        "cs = plt.contourf(xx, yy, Z)\n",
        "plt.axis(\"tight\")\n",
        "\n",
        "# Plot the training points\n",
        "for i, n in zip(range(2), [\"Benign\", \"Malignant\"]):\n",
        "    idx = np.where(y_train == i)\n",
        "    idx = idx[0]\n",
        "    plt.scatter(X_train.iloc[idx, 0], X_train.iloc[idx, 1],\n",
        "                label=\"Class %s\" % n)\n",
        "plt.xlim(x_min, x_max)\n",
        "plt.ylim(y_min, y_max)\n",
        "plt.legend(loc='upper right', frameon=True)\n",
        "plt.xlabel('Radius Mean')\n",
        "plt.ylabel('Texture Mean')\n",
        "plt.title('Decision Boundary')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgdtdX3NLDzA"
      },
      "source": [
        "# Receiver Operating Characteristic Curves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVJEtVNi2aJ9"
      },
      "source": [
        "# Re-train adaboost with full training set\n",
        "bdt.fit(training_values, training_labels)\n",
        "\n",
        "testing_predictions = bdt.predict_proba(testing_values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GUhCNigJ6Uv"
      },
      "source": [
        "print(testing_predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlXGTO-c3iwe"
      },
      "source": [
        "# Compute ROC curve and ROC area for each class\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "for i in range(2):\n",
        "    fpr[i], tpr[i], _ = metrics.roc_curve(testing_labels, testing_predictions[:,i])\n",
        "    roc_auc[i] = metrics.auc(fpr[i], tpr[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWKOsUYPM5jp"
      },
      "source": [
        "print(f\"{fpr[0]}\")\n",
        "print(f\"{fpr[1]}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "loFpjasbNHjp"
      },
      "source": [
        "len(fpr[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xoxw-Rdg30DQ"
      },
      "source": [
        "plt.figure()\n",
        "lw = 2\n",
        "plt.plot(fpr[1], tpr[1], color='darkorange',\n",
        "         lw=lw, label=f'ROC (AUC = {roc_auc[1]})')\n",
        "plt.plot([0, 1], [0, 1], color='navy', \n",
        "         lw=lw, linestyle='--', label=f'Random')\n",
        "plt.xlim([-0.05, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver operating characteristic (ROC) curve')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0HAoi9QKWz3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}