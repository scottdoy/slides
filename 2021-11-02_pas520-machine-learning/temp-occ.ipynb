{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8353f6f",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    },
    "tags": []
   },
   "source": [
    "# PAS 520: Machine Learning and AI\n",
    "\n",
    "- Scott Doyle\n",
    "- 2021-11-02\n",
    "- Dept. of Pathology & Anatomical Sciences\n",
    "- scottdoy@buffalo.edu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45e6ff58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#from ipywidgets import interact\n",
    "#import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94c1c4c6",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "#import torch\n",
    "#from torch import nn\n",
    "#from torch import optim\n",
    "#import torch.nn.functional as F\n",
    "\n",
    "#from torchvision.datasets import MNIST\n",
    "#from torchvision.utils import make_grid\n",
    "#from torchvision.transforms import ToTensor\n",
    "#from torchvision import datasets, transforms, models, utils\n",
    "#from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "from skimage.io import imread\n",
    "\n",
    "#from plotly.subplots import make_subplots\n",
    "#import plotly.express as px\n",
    "#import plotly.graph_objects as go\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25b21086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an output dir for the models, if one doesn't exist\n",
    "save_model_dir = os.path.join('data', 'mnist-models')\n",
    "os.makedirs(save_model_dir, exist_ok=True)\n",
    "\n",
    "# Grab the colormap to use from matplotlib\n",
    "cmap = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "\n",
    "# Set various font sizes\n",
    "global_font_size = 20\n",
    "title_font_size = 30\n",
    "hoverlabel_font_size = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d60ea52",
   "metadata": {},
   "source": [
    "# Breast Cancer: Cytology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b00d232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load feature values\n",
    "all_features = pd.read_csv('data/breast_cytology_features/wisconsin_breast_cancer_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7522be8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n",
       "0  ...         25.38          17.33           184.60      2019.0   \n",
       "1  ...         24.99          23.41           158.80      1956.0   \n",
       "2  ...         23.57          25.53           152.50      1709.0   \n",
       "3  ...         14.91          26.50            98.87       567.7   \n",
       "4  ...         22.54          16.67           152.20      1575.0   \n",
       "\n",
       "   smoothness_worst  compactness_worst  concavity_worst  concave points_worst  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   symmetry_worst  fractal_dimension_worst  \n",
       "0          0.4601                  0.11890  \n",
       "1          0.2750                  0.08902  \n",
       "2          0.3613                  0.08758  \n",
       "3          0.6638                  0.17300  \n",
       "4          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0b5bdb7",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of ['Row'] are in the columns\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_108554/3722214662.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Remove NaN values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcomplete_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcomplete_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomplete_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Row'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/occ/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/occ/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mset_index\u001b[0;34m(self, keys, drop, append, inplace, verify_integrity)\u001b[0m\n\u001b[1;32m   5449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5450\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5451\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"None of {missing} are in the columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5453\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of ['Row'] are in the columns\""
     ]
    }
   ],
   "source": [
    "# Remove NaN values\n",
    "complete_features = all_features.dropna()\n",
    "complete_features = complete_features.set_index('Row')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9edf5569",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9631313d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide dataframe\n",
    "feature_data = complete_features.copy()\n",
    "feature_data = feature_data.drop(['proggroup', 'poigroup'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ab8731",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0013183",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_names = complete_features.copy()['Row']\n",
    "prog_group = complete_features.copy()['proggroup']\n",
    "poi_group = complete_features.copy()['poigroup']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4576a1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale Features\n",
    "scaled_features = StandardScaler().fit_transform(feature_data.values)\n",
    "scaled_features_df = pd.DataFrame(scaled_features, index=feature_data.index, columns=feature_data.columns)\n",
    "\n",
    "# Create label vectors\n",
    "prog_labels = LabelEncoder().fit_transform(prog_group)\n",
    "poi_labels = LabelEncoder().fit_transform(poi_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616fa15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up an interactive scatterplot\n",
    "def display_unsupervised(f1, f2):\n",
    "    X1 = scaled_features_df[f1]\n",
    "    X2 = scaled_features_df[f2]\n",
    "    \n",
    "    plt.scatter(X1, X2)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10b46ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "interact(display_unsupervised, f1=scaled_features_df.columns, f2=scaled_features_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f657340e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up an interactive scatterplot\n",
    "def display_progression(f1, f2):\n",
    "    X1 = scaled_features_df[f1]\n",
    "    X2 = scaled_features_df[f2]\n",
    "    \n",
    "    plt.scatter(X1, X2, c=prog_labels)\n",
    "    plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081e8cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "interact(display_progression, f1=scaled_features_df.columns, f2=scaled_features_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde085a6",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load up the geometry feature data\n",
    "occ_feat_path = os.path.join('data', 'occ_features_old', 'all_features_old.csv')\n",
    "occ_df = pd.read_csv(occ_feat_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36036d30",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set the index to be the row name\n",
    "occ_df = occ_df.set_index('Row')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24b55f3",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "occ_poi = occ_df.copy()\n",
    "#occ_values = occ_poi.drop(['ROI', 'Occult metastasis', 'progression', 'wpoi'], axis=1)\n",
    "occ_values = occ_poi.drop(['Progression', 'POI'], axis=1)\n",
    "\n",
    "poi_labels = occ_poi[['POI']].copy()\n",
    "prog_labels = occ_poi[['Progression']].copy()\n",
    "#met_labels = occ_poi[['Occult metastasis']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b006a6c0",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "poi_labels = label_encoder.fit_transform(poi_labels)\n",
    "prog_labels = label_encoder.fit_transform(prog_labels)\n",
    "# met_labels = label_encoder.fit_transform(met_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d16273",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate feature correlations\n",
    "corr_matrix = occ_values.corr()\n",
    "upper_triangle_locations = np.triu( np.ones(corr_matrix.shape), k=1).astype(bool)\n",
    "upper = corr_matrix.where(upper_triangle_locations)\n",
    "\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.9)]\n",
    "print('{} columns to drop: {}'.format(len(to_drop), to_drop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc0beda",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "occ_slim = occ_values.drop(occ_values[to_drop], axis=1)\n",
    "occ_slim.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89012e0",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Scale the dataset\n",
    "\n",
    "\n",
    "input_pipeline = Pipeline([\n",
    "        ('std_scaler', StandardScaler()),\n",
    "#         ('feat_selection', SelectKBest(f_classif, k=5))\n",
    "    ])\n",
    "\n",
    "# This does the same thing, adds a name automatically\n",
    "# input_pipeline = make_pipeline(StandardScaler(), SelectKBest(chi2, k=2))\n",
    "transformed_values = input_pipeline.fit_transform(occ_slim)\n",
    "\n",
    "# Stuff these values back into a dataframe\n",
    "training_df = pd.DataFrame(transformed_values, index=occ_slim.index, columns=occ_slim.columns)\n",
    "training_df['POI'] = poi_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2494efe2",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620fd272",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# feat_order = np.argsort(input_pipeline['feat_selection'].scores_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1054258c",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# feat_set = ['mom5_satDist', 'mean_triArea', 'skew_triArea', 'geo_mean_triArea','mom5_triLength', 'mom5_satWave']\n",
    "# feat_set = ['edge_min_value', 'edge_max_value','edge_interquartile_range','edge_median','edge_variance','edge_skewness','edge_hyperskewness_5th_moment', 'tri_max_value', 'tri_interquartile_range', 'tri_skewness']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c487999",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = px.scatter_matrix(training_df,\n",
    "                        dimensions=training_df.columns[:5],\n",
    "                        color=\"POI\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71636c05",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = px.scatter_matrix(training_df,\n",
    "                        dimensions=training_df.columns[5:10],\n",
    "                        color=\"POI\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73576a28",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = px.scatter_matrix(training_df,\n",
    "                        dimensions=training_df.columns[10:15],\n",
    "                        color=\"POI\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfb150d",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = px.scatter_matrix(training_df,\n",
    "                        dimensions=training_df.columns[15:20],\n",
    "                        color=\"POI\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d2bebc",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = px.scatter_matrix(training_df,\n",
    "                        dimensions=training_df.columns[21:25],\n",
    "                        color=\"POI\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f14aab",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = px.scatter_matrix(training_df,\n",
    "                        dimensions=training_df.columns[25:],\n",
    "                        color=\"POI\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1966730",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a pipeline to scale the features and then select the best\n",
    "# fig = px.scatter_matrix(occ_poi_data,\n",
    "#     dimensions=wpoi_plotcols,\n",
    "#     color=\"wpoi\")\n",
    "fig = px.scatter_matrix(training_df,\n",
    "#                         dimensions=feat_set,\n",
    "                       color=\"POI\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae5cad0",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fig = px.scatter(training_df,x=\"mom5_satDist\", y=\"mom5_satWave\", color=\"poi\")\n",
    "# fig.update_traces()\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf49b8b",
   "metadata": {},
   "source": [
    "# Neural Network Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15567eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that by default, the MNIST data is NOT in PyTorch Format\n",
    "# Passing `transform=ToTensor()` will convert the data appropriately\n",
    "mnist_data = MNIST('./data', download=True, train=True, transform=ToTensor())\n",
    "\n",
    "batch_size = 4\n",
    "training_data = DataLoader(mnist_data, batch_size=batch_size)\n",
    "\n",
    "# Recall that the data is the first element of the tuple in the \"training.pt\" file\n",
    "print(f'The dataset size is: {len(training_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b21748",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_data = next(iter(training_data))\n",
    "sample_images = sample_data[0]\n",
    "sample_labels = sample_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5263bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8956a309",
   "metadata": {
    "tags": [
     "to_remove"
    ]
   },
   "outputs": [],
   "source": [
    "fig = px.imshow(np.array(sample_images[1]), facet_col=0, color_continuous_scale='gray')\n",
    "\n",
    "fig.update_layout(\n",
    "    coloraxis_showscale=False,\n",
    "    xaxis=dict(\n",
    "        showticklabels=False\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        showticklabels=False\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.for_each_annotation(lambda a: a.update(text=\"\"))\n",
    "\n",
    "fig.write_html(\"img/plot_mnist_sample.html\", include_plotlyjs='cdn')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62a276b",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "to_remove"
    ]
   },
   "outputs": [],
   "source": [
    "# # Reshape the sample data\n",
    "# sample_data_reshaped = sample_data.view(num_samples, -1)\n",
    "# sample_data_reshaped = sample_data_reshaped.numpy()\n",
    "\n",
    "# Define the red rectangles that will go on the images\n",
    "x = 10.5\n",
    "y = 9.45\n",
    "num_rows = 28\n",
    "num_cols = 28\n",
    "\n",
    "sample_image = np.array(sample_images[0])\n",
    "fig = px.imshow(sample_image, facet_col=0, color_continuous_scale='gray')\n",
    "\n",
    "# Shape defined programatically\n",
    "fig.add_shape(\n",
    "    type='rect',\n",
    "    x0=x, x1=x+5, y0=y, y1=y+1,\n",
    "    xref='x', yref='y',\n",
    "    line_color='red'\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "   coloraxis_showscale=False,\n",
    ")\n",
    "fig.update_xaxes(showticklabels=False).update_yaxes(showticklabels=False)\n",
    "\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc574d1",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_unrolled_data(label_to_grab, num_to_grab=100):\n",
    "    \n",
    "    class_data = []\n",
    "    for idx, batch in enumerate(training_data):\n",
    "        for image, label in zip(batch[0], batch[1]):\n",
    "            if label == label_to_grab:\n",
    "                class_data.append(image)\n",
    "\n",
    "    # Slice the data to only look at the first few samples\n",
    "    class_data = class_data[:num_to_grab]\n",
    "    \n",
    "    # \"unroll\" the data to produce an image that is \n",
    "    # (28*28, num_to_grab) large\n",
    "    class_data_unrolled = np.hstack([np.array(x).reshape(28*28,1) for x in class_data])\n",
    "    \n",
    "    return class_data_unrolled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9c150e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_zeros = get_unrolled_data(0, num_to_grab=1000)\n",
    "class_ones = get_unrolled_data(1, num_to_grab=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829befbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.imshow(class_zeros, color_continuous_scale='gray')\n",
    "\n",
    "fig.update_layout(\n",
    "    coloraxis_showscale=False,\n",
    "    xaxis=dict(\n",
    "        showticklabels=False\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        showticklabels=False\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771b3b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(1,2)\n",
    "\n",
    "fig.add_trace(px.imshow(np.array(sample_images[1]), facet_col=0).data[0], 1, 1)\n",
    "fig.add_trace(px.imshow(class_zeros).data[0], 1, 2)\n",
    "\n",
    "layout = px.imshow(class_zeros, color_continuous_scale='gray').layout\n",
    "fig.layout.coloraxis = layout.coloraxis\n",
    "\n",
    "fig.update_layout(\n",
    "    coloraxis_showscale=False,\n",
    "    xaxis=dict(\n",
    "        showticklabels=False\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        showticklabels=False\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.write_html(\"img/plot_mnist_zero.html\", include_plotlyjs='cdn')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de486464",
   "metadata": {
    "tags": [
     "to_remove"
    ]
   },
   "outputs": [],
   "source": [
    "fig = make_subplots(1,2)\n",
    "\n",
    "# Make this just the unrolled classes\n",
    "\n",
    "# Doing this from https://stackoverflow.com/questions/64268081/creating-a-subplot-of-images-with-plotly\n",
    "fig.add_trace(px.imshow(class_zeros).data[0], 1, 1)\n",
    "fig.add_trace(px.imshow(class_ones).data[0], 1, 2)\n",
    "\n",
    "fig.update_xaxes(title=\"All Zeros\", col=1)\n",
    "fig.update_xaxes(title=\"All Ones\", col=2)\n",
    "\n",
    "layout = px.imshow(class_ones, color_continuous_scale='gray').layout\n",
    "fig.layout.coloraxis = layout.coloraxis\n",
    "\n",
    "fig.update_layout(\n",
    "    coloraxis_showscale=False\n",
    ")\n",
    "\n",
    "fig.write_html(\"img/plot_mnist_comparison.html\", include_plotlyjs='cdn')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7c1df8",
   "metadata": {},
   "source": [
    "# Nuclei Classification Images (In Plotly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81b7f3d",
   "metadata": {
    "tags": [
     "to_remove"
    ]
   },
   "outputs": [],
   "source": [
    "img1 = imread('img/he_cell01_resized.png')\n",
    "img2 = imread('img/he_cell02_resized.png')\n",
    "\n",
    "fig = make_subplots(1,2)\n",
    "fig.add_trace(px.imshow(img1).data[0], 1, 1)\n",
    "fig.add_trace(px.imshow(img2).data[0], 1, 2)\n",
    "\n",
    "fig.write_html(\"img/plot_nuclei_comparison.html\", include_plotlyjs='cdn')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43494908",
   "metadata": {
    "tags": [
     "to_remove"
    ]
   },
   "outputs": [],
   "source": [
    "img1 = imread('img/he_nocell01_resized.png')\n",
    "img2 = imread('img/he_nocell02_resized.png')\n",
    "\n",
    "fig = make_subplots(1,2)\n",
    "fig.add_trace(px.imshow(img1).data[0], 1, 1)\n",
    "fig.add_trace(px.imshow(img2).data[0], 1, 2)\n",
    "\n",
    "fig.write_html(\"img/plot_stroma_comparison.html\", include_plotlyjs='cdn')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d7ccfb",
   "metadata": {},
   "source": [
    "# Nuclei Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6184fe74",
   "metadata": {
    "id": "MxhvI4bBPPq9",
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the dataset into a Pandas dataframe\n",
    "img_dir = os.path.join('data', 'breast_cancer_nuclei', 'patches_64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27df1712",
   "metadata": {
    "id": "9TEvKmqta9Wi",
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "args = {}\n",
    "\n",
    "# Training and testing batch size\n",
    "args[\"train_batch_size\"] = 4#8 # 64\n",
    "args[\"test_batch_size\"] = 4#8 # 1000\n",
    "\n",
    "# How long to train for\n",
    "args[\"epochs\"] = 2 # 100\n",
    "\n",
    "# Learning rate: \"Speed\" with which the optimizer adjusts weights\n",
    "args[\"lr\"] = 0.01\n",
    "\n",
    "# Momentum: How quickly the weights respond to changing gradients\n",
    "args[\"momentum\"] = 0.5\n",
    "\n",
    "# Whether to use CUDA or not\n",
    "args[\"no_cuda\"] = False\n",
    "\n",
    "# Seed for reproducible training\n",
    "args[\"seed\"] = 1\n",
    "\n",
    "# How often to spit out log / progress updates\n",
    "args[\"log_interval\"] = 10\n",
    "\n",
    "# Whether to save the trained model\n",
    "args[\"save_model\"] = False\n",
    "\n",
    "# Decide whether to use CUDA\n",
    "use_cuda = not args[\"no_cuda\"] and torch.cuda.is_available()\n",
    "\n",
    "# Set the seed\n",
    "torch.manual_seed(args[\"seed\"])\n",
    "\n",
    "# Select the device to use based on the `use_cuda` flag\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "# Keyword arguments for the dataloader\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262541ae",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "data_transform = transforms.Compose(\n",
    "    [transforms.Resize(64),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "nuclei_trainset = datasets.ImageFolder(root=os.path.join(img_dir, 'train'), transform=data_transform)\n",
    "nuclei_testset = datasets.ImageFolder(root=os.path.join(img_dir, 'test'), transform=data_transform)\n",
    "\n",
    "nuclei_trainloader = torch.utils.data.DataLoader(nuclei_trainset, batch_size=args['train_batch_size'],\n",
    "                                                 shuffle=True, num_workers=2)\n",
    "nuclei_testloader = torch.utils.data.DataLoader(nuclei_trainset, batch_size=args['test_batch_size'],\n",
    "                                                 shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('nonnuclei', 'nuclei')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8425771",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def imshow(images):\n",
    "    img_grid = utils.make_grid(images)\n",
    "    img = img_grid / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(20,10))\n",
    "    ax.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    ax.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf3430b",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Get some random training images (one iteration of the dataloader)\n",
    "dataiter = iter(nuclei_trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "num_samples = images.shape[0]\n",
    "images_reshaped = np.moveaxis(np.array(images), 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8218327d",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34259369",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    },
    "tags": [
     "to_remove"
    ]
   },
   "outputs": [],
   "source": [
    "# Preate a plotly matrix of the images\n",
    "\n",
    "fig = px.imshow(images_reshaped, facet_col=0, zmin=-1, zmax=1)\n",
    "\n",
    "fig.update_layout(coloraxis_showscale=False)\n",
    "fig.update_xaxes(showticklabels=False).update_yaxes(showticklabels=False)\n",
    "\n",
    "fig.for_each_annotation(lambda a: a.update(text=\"\"))\n",
    "\n",
    "for idx in range(num_samples):\n",
    "    fig.layout.annotations[idx]['text'] = classes[labels[idx]]\n",
    "\n",
    "fig.write_html(\"img/plot_nuclei_classes.html\", include_plotlyjs='cdn')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7197ca",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "class NucleiNet(nn.Module):\n",
    "    def __init__(self, disp_size):\n",
    "        super(NucleiNet, self).__init__()\n",
    "        \n",
    "        # Flag whether or not to print out information about the tensor\n",
    "        self.disp_size = disp_size\n",
    "        \n",
    "        # nn.Conv2d(in_channels, out_channels, kernel_size)\n",
    "        self.conv1 = nn.Conv2d(3, 6, 3, 1, 1)\n",
    "        \n",
    "        # nn.MaxPool2d(kernel_size, stride)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3, 1, 1)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        # nn.Linear(in_features, out_features)\n",
    "        self.fc1 = nn.Linear(16 * 16 * 16, 512)\n",
    "        self.fc2 = nn.Linear(512, 120)\n",
    "        self.fc3 = nn.Linear(120, 84)\n",
    "        self.fc4 = nn.Linear(84, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.disp_size:\n",
    "            print('x input size:\\t\\t\\t\\t\\t{}'.format(x.shape))\n",
    "\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        if self.disp_size:\n",
    "            print('After first block [Conv->Relu->Pool]:\\t\\t{}'.format(x.shape))\n",
    "        \n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        if self.disp_size:\n",
    "            print('After second block [Conv->Relu->Pool]:\\t\\t{}'.format(x.shape))\n",
    "\n",
    "        x = x.view(-1, 16 * 16 * 16)\n",
    "        if self.disp_size:\n",
    "            print('After reshape:\\t\\t\\t\\t\\t{}'.format(x.shape))\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        if self.disp_size:\n",
    "            print('After first linear layer:\\t\\t\\t{}'.format(x.shape))\n",
    "\n",
    "        x = F.relu(self.fc2(x))\n",
    "        if self.disp_size:\n",
    "            print('After second linear layer:\\t\\t\\t{}'.format(x.shape))\n",
    "            \n",
    "        x = F.relu(self.fc3(x))\n",
    "        if self.disp_size:\n",
    "            print('After third linear layer:\\t\\t\\t{}'.format(x.shape))\n",
    "            \n",
    "        x = self.fc4(x)\n",
    "        if self.disp_size:\n",
    "            print('After fourth linear layer:\\t\\t\\t{}'.format(x.shape))\n",
    "            print(' ')\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6979abb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "id": "fPu-oS7hQaaZ",
    "outputId": "2bcf6e41-484d-47bb-b5a4-44763753367e",
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a model and set the \"disp_size\" to True, so it will print out the size of each layer\n",
    "nuclei_net = NucleiNet(disp_size=True)\n",
    "\n",
    "# Run an image batch through just to get some output\n",
    "_ = nuclei_net(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77250d8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "id": "PoZhOd3eYWKI",
    "outputId": "945eef6c-23fd-4d4d-f2ae-294fe8933c2e",
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# In PyTorch you can list out the different layers as \"children\" of the model\n",
    "list(nuclei_net.children())[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b6572b",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# You can also pull out specific layers of the model and use them to build a new one\n",
    "# Here we look at the first four layers, which include the two convolutional and pooling layers\n",
    "nuclei_features = nn.Sequential(*list(nuclei_net.children())[0:4])\n",
    "\n",
    "print(\"First three layers:\")\n",
    "print(nuclei_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b76330",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "635G13q7Qk8M",
    "outputId": "333f1e22-acaf-4c8c-cc64-a8efee071efb",
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "outputs = nuclei_features(images)\n",
    "print(\"size of outputs: {}\".format(outputs.shape))\n",
    "\n",
    "# Which image in the batch do you want to look at?\n",
    "target_img = 0\n",
    "\n",
    "# Set up the filter block\n",
    "num_channels = outputs.shape[0]\n",
    "\n",
    "# Set up the display of the filter block for this image\n",
    "rows = int(np.floor(np.sqrt(num_channels)))\n",
    "if np.mod(np.sqrt(num_channels), 1) != 0:\n",
    "    # There is a remainder\n",
    "    cols = rows + 1\n",
    "else:\n",
    "    cols = rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdc4f95",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    },
    "tags": [
     "to_remove"
    ]
   },
   "outputs": [],
   "source": [
    "# Plot the original\n",
    "fig = px.imshow(np.transpose(images[target_img].cpu() / 2 + 0.5, (1,2,0)))\n",
    "fig.update_xaxes(showticklabels=False, title=\"Original Image\").update_yaxes(showticklabels=False)\n",
    "fig.write_html(\"img/plot_nuclei_example.html\", include_plotlyjs='cdn')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361e9612",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    },
    "tags": [
     "to_remove"
    ]
   },
   "outputs": [],
   "source": [
    "output_numpy = outputs[target_img,:,:,:].detach().cpu()\n",
    "fig = px.imshow(output_numpy, facet_col=0, facet_col_wrap=4, color_continuous_scale='gray')\n",
    "\n",
    "fig.update_layout(coloraxis_showscale=False)\n",
    "fig.update_xaxes(showticklabels=False).update_yaxes(showticklabels=False)\n",
    "\n",
    "fig.for_each_annotation(lambda a: a.update(text=\"\"))\n",
    "\n",
    "for idx in range(output_numpy.shape[0]):\n",
    "    fig.layout.annotations[idx]['text'] = f\"Filter {idx}\"\n",
    "\n",
    "fig.write_html(\"img/plot_nuclei_filters.html\", include_plotlyjs='cdn')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c795e3c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "m3WZFuJ3Q08y",
    "outputId": "0afbdea0-c246-4600-e567-9c3f5f4f515f",
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "nuclei_net = NucleiNet(disp_size=False)\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(\"Device: {}\".format(device))\n",
    "\n",
    "# move model to the right device\n",
    "nuclei_net.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(nuclei_net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb63881b",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "list_loss = []\n",
    "avg_loss = []\n",
    "for epoch in range(10):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(nuclei_trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        #inputs, labels = data\n",
    "\n",
    "        # Move to the GPU\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = nuclei_net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 20 == 19:    # print every 20 mini-batches\n",
    "            print('[%d, %5d] loss: %.5f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 20))\n",
    "            list_loss.append(running_loss / 20)\n",
    "            running_loss = 0.0\n",
    "    \n",
    "    # Record average loss for this epoch\n",
    "    avg_loss.append(np.mean(list_loss))\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fee1164",
   "metadata": {
    "tags": [
     "to_remove"
    ]
   },
   "outputs": [],
   "source": [
    "fig = px.line(y=avg_loss, labels={'x':'Training Epoch', 'y':'Loss Value'})\n",
    "fig.write_html(\"img/plot_nuclei_training.html\", include_plotlyjs='cdn')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82b0308",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "#dataiter = iter(nuclei_testloader)\n",
    "images, labels = dataiter.next()\n",
    "images = images.to(device)\n",
    "\n",
    "outputs = nuclei_net(images)\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "images_reshaped = np.moveaxis(np.array(images.cpu()), 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c235ca",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    },
    "tags": [
     "to_remove"
    ]
   },
   "outputs": [],
   "source": [
    "# Preate a plotly matrix of the images\n",
    "\n",
    "fig = px.imshow(images_reshaped, facet_col=0, zmin=-1, zmax=1)\n",
    "\n",
    "fig.update_layout(coloraxis_showscale=False)\n",
    "fig.update_xaxes(showticklabels=False).update_yaxes(showticklabels=False)\n",
    "\n",
    "fig.for_each_annotation(lambda a: a.update(text=\"\"))\n",
    "\n",
    "for idx in range(num_samples):\n",
    "    fig.layout.annotations[idx]['text'] = f'{classes[predicted[idx]]} : {classes[labels[idx]]}'\n",
    "\n",
    "fig.write_html(\"img/plot_nuclei_inference.html\", include_plotlyjs='cdn')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbd0a2a",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    },
    "tags": [
     "to_remove"
    ]
   },
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in nuclei_testloader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = nuclei_net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the {} testing images: {} %'.format(\n",
    "    total, 100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8515fd59",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    },
    "tags": [
     "to_remove"
    ]
   },
   "outputs": [],
   "source": [
    "img = imread(\"img/he_tissue_sample.jpg\")\n",
    "img_gt = imread(\"img/ground_truth.png\")\n",
    "\n",
    "fig = make_subplots(1,2)\n",
    "fig.add_trace(px.imshow(img).data[0], 1, 1)\n",
    "fig.add_trace(px.imshow(img_gt).data[0], 1, 2)\n",
    "\n",
    "fig.update_layout(coloraxis_showscale=False)\n",
    "fig.update_xaxes(showticklabels=False).update_yaxes(showticklabels=False)\n",
    "\n",
    "fig.update_xaxes(title=\"Original Image\", col=1)\n",
    "fig.update_xaxes(title=\"Ground Truth\", col=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6cbee4",
   "metadata": {
    "tags": [
     "to_remove"
    ]
   },
   "outputs": [],
   "source": [
    "img_seg = imread(\"img/segmentation.jpg\")\n",
    "img_gt = imread(\"img/ground_truth.png\")\n",
    "\n",
    "fig = make_subplots(1,2)\n",
    "fig.add_trace(px.imshow(img_seg).data[0], 1, 1)\n",
    "fig.add_trace(px.imshow(img_gt).data[0], 1, 2)\n",
    "\n",
    "fig.update_layout(coloraxis_showscale=False)\n",
    "fig.update_xaxes(showticklabels=False).update_yaxes(showticklabels=False)\n",
    "\n",
    "fig.update_xaxes(title=\"Segmented Image\", col=1)\n",
    "fig.update_xaxes(title=\"Ground Truth\", col=2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:occ]",
   "language": "python",
   "name": "conda-env-occ-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
